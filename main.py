#!/usr/bin/env python3
"""
AI Assistant for Raspberry Pi with Personalized Wake Words and Face Recognition
Created for Sophia (wake word: "Miley") and Eladriel (wake word: "Dino")
Enhanced with automatic face recognition, personalized greetings, and universal object identification
"""

import os
import sys
import time
import logging
import threading
import signal
from typing import Optional
from datetime import datetime

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from config import Config
    from audio_utils import AudioManager, setup_premium_tts_engines
    from wake_word_detector import WakeWordDetector
    from dinosaur_identifier import DinosaurIdentifier
    from object_identifier import ObjectIdentifier
    from smart_camera_detector import SmartCameraDetector
    import openai
    import pyttsx3
    import speech_recognition as sr
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Please install required packages: pip install -r requirements.txt")
    sys.exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AIAssistant:
    def __init__(self):
        """Initialize the AI Assistant with Face Recognition and Universal Object Identification"""
        self.config = Config()
        self.running = False
        self.current_user = None
        
        # Setup OpenAI client
        self.client = openai.OpenAI(api_key=self.config.openai_api_key)
        
        # Setup premium OpenAI TTS engines with natural human voices
        logger.info("üéôÔ∏è Setting up premium OpenAI text-to-speech voices...")
        self.sophia_tts, self.eladriel_tts = setup_premium_tts_engines(self.client)
        
        # Setup audio components
        self.audio_manager = AudioManager()
        self.recognizer = sr.Recognizer()
        
        # Setup wake word detector
        self.wake_word_detector = WakeWordDetector(self.config)
        
        # Setup dinosaur identifier for Eladriel (specialized for dinosaurs)
        logger.info("Setting up dinosaur identification for Eladriel...")
        self.dinosaur_identifier = DinosaurIdentifier(self.client, self.config)
        
        # Setup universal object identifier for both users
        logger.info("üîç Setting up universal object identification system...")
        self.object_identifier = ObjectIdentifier()
        
        # Setup face recognition system
        logger.info("üé≠ Setting up face recognition system...")
        self.face_detector = SmartCameraDetector(model_size='n', confidence_threshold=0.4)
        self.face_recognition_thread = None
        self.face_recognition_active = False
        self.last_face_greeting = {}  # Track when we last greeted each person
        self.face_greeting_cooldown = 30  # seconds between face greetings
        
        # Parent mode settings
        self.quiet_mode = False
        
        # User profiles with personalized settings
        self.users = {
            'sophia': {
                'name': 'Sophia',
                'wake_word': 'miley',
                'personality': 'friendly, encouraging, and supportive',
                'greeting': "Hi Sophia! I'm here to help you with anything you need! My voice sounds so much more natural now!",
                'face_greeting': "Hello Sophia! I can see you! üëã How wonderful to see your beautiful face!",
                'tts_engine': self.sophia_tts,
                'special_commands': ['help', 'what can you do', 'identify this', 'what is this', 'tell me about this']
            },
            'eladriel': {
                'name': 'Eladriel',
                'wake_word': 'dino',
                'personality': 'playful, curious, and energetic',
                'greeting': "Hey Eladriel! Ready for some fun discoveries? I can identify your dinosaur toys and any other objects! And listen to how natural my voice sounds now!",
                'face_greeting': "Hey Eladriel! I see you there! ü¶ï Ready for some dinosaur adventures?",
                'tts_engine': self.eladriel_tts,
                'special_commands': ['identify dinosaur', 'identify this', 'what is this', 'tell me about this', 'show me camera', 'dinosaur tips', 'help']
            },
            'parent': {
                'name': 'Parent',
                'wake_word': 'assistant',
                'personality': 'professional, intelligent, and efficient',
                'greeting': self.get_parent_greeting(),
                'face_greeting': self.get_parent_face_greeting(),
                'tts_engine': self.sophia_tts,  # Use calm voice for parent mode
                'special_commands': [
                    'help', 'status report', 'system check', 'quiet mode on', 'quiet mode off',
                    'identify this', 'what is this', 'tell me about this', 'show me camera',
                    'check on kids', 'home automation', 'schedule reminder', 'weather',
                    'news update', 'shopping list', 'calendar', 'notes'
                ]
            }
        }
        
        logger.info("üöÄ AI Assistant initialized with premium natural voices, face recognition, and universal object identification!")

    def get_parent_greeting(self) -> str:
        """Get time-appropriate greeting for parent mode."""
        current_hour = datetime.now().hour
        
        if current_hour >= 21 or current_hour <= 6:  # 9 PM to 6 AM
            return "Hello! Parent mode activated. I'm ready to assist you with any requests. Speaking quietly to avoid waking the children."
        else:
            return "Hello! Parent mode activated. I'm ready to assist you with any requests."

    def get_parent_face_greeting(self) -> str:
        """Get time-appropriate face greeting for parent mode."""
        current_hour = datetime.now().hour
        
        if current_hour >= 21 or current_hour <= 6:  # 9 PM to 6 AM
            return "Hello! I see you. Parent mode ready - speaking softly."
        else:
            return "Hello! I see you. Parent mode ready."

    def should_greet_face(self, person_name: str) -> bool:
        """Check if we should greet this person based on face detection cooldown."""
        current_time = time.time()
        last_time = self.last_face_greeting.get(person_name.lower(), 0)
        
        if current_time - last_time > self.face_greeting_cooldown:
            self.last_face_greeting[person_name.lower()] = current_time
            return True
        
        return False

    def handle_face_detection(self):
        """Background thread for face recognition and automatic conversation activation."""
        logger.info("üëÅÔ∏è Face recognition thread started")
        
        try:
            # Start camera
            if not self.face_detector.start_camera():
                logger.error("Failed to start camera for face recognition")
                return
            
            while self.face_recognition_active and self.running:
                try:
                    # Capture frame
                    ret, frame = self.face_detector.cap.read()
                    if not ret:
                        continue
                    
                    # Detect faces
                    face_detections = self.face_detector.detect_faces(frame)
                    
                    # Process detected faces
                    for face in face_detections:
                        if face['name'] != "Unknown" and face['confidence'] > 0.6:
                            person_name = face['name'].lower()
                            
                            # Check if this person is in our user profiles
                            if person_name in self.users:
                                # If no one is currently in conversation, start automatic conversation
                                if not self.current_user and self.should_greet_face(person_name):
                                    # Get appropriate face greeting (time-aware for parent mode)
                                    if person_name == 'parent':
                                        face_greeting = self.get_parent_face_greeting()
                                    else:
                                        face_greeting = self.users[person_name].get('face_greeting', f"Hello {person_name.title()}!")
                                    
                                    logger.info(f"üëã Face detected: {person_name.title()} - Starting automatic conversation")
                                    print(f"üéâ Face detected: {person_name.title()}! Starting automatic conversation...")
                                    
                                    # Speak greeting and automatically start conversation
                                    self.speak(face_greeting, person_name)
                                    
                                    # Start automatic conversation mode (no wake word needed!)
                                    threading.Thread(
                                        target=self.handle_automatic_conversation, 
                                        args=(person_name,), 
                                        daemon=True
                                    ).start()
                    
                    # Small delay to prevent excessive CPU usage
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"Error in face detection loop: {e}")
                    time.sleep(1)
        
        except Exception as e:
            logger.error(f"Face recognition thread error: {e}")
        finally:
            if self.face_detector.cap:
                self.face_detector.cap.release()
            logger.info("üëÅÔ∏è Face recognition thread stopped")

    def handle_automatic_conversation(self, user: str):
        """Handle automatic conversation triggered by face detection."""
        if self.current_user:  # Someone else is already in conversation
            return
        
        self.current_user = user
        user_info = self.users[user]
        
        logger.info(f"ü§ñ Starting automatic conversation with {user.title()}")
        print(f"üí¨ Automatic conversation mode activated for {user.title()}!")
        print("üé§ I'm listening... (say 'goodbye' to end, or I'll timeout after 1 minute of silence)")
        
        # Start conversation loop - keep listening until user says goodbye or timeout
        conversation_active = True
        conversation_timeout_count = 0
        max_timeouts = 12  # 12 timeouts of 5 seconds each = 1 minute total
        
        while conversation_active and self.running and self.current_user == user:
            # Listen for their request with a 5-second timeout
            user_input = self.listen_for_speech(timeout=5)
            
            if user_input:
                conversation_timeout_count = 0  # Reset timeout counter
                
                # Check if user wants to end conversation
                if self.is_conversation_ending(user_input):
                    farewell_messages = {
                        'sophia': "Goodbye Sophia! I'm always here when you need me. Have a wonderful day!",
                        'eladriel': "See you later Eladriel! Keep exploring and learning about dinosaurs! Roar!",
                        'parent': "Goodbye! Parent mode deactivated. All systems remain operational for the children. Call 'Assistant' anytime you need me."
                    }
                    self.speak(farewell_messages.get(user, "Goodbye! Talk to you soon!"), user)
                    conversation_active = False
                    break
                
                # Check for special commands first
                special_response = self.handle_special_commands(user_input, user)
                
                if special_response:
                    self.speak(special_response, user)
                else:
                    # Process with OpenAI for regular conversation
                    import asyncio
                    try:
                        response = asyncio.run(self.process_with_openai(user_input, user))
                        self.speak(response, user)
                    except Exception as e:
                        logger.error(f"Error processing request: {e}")
                        self.speak("I'm sorry, something went wrong. Let me try again.", user)
                
                # After responding, give a subtle cue that we're still listening
                time.sleep(0.5)  # Brief pause
                print(f"üí¨ Still listening to {user.title()}... (say 'goodbye' to end)")
                
            else:
                # No speech detected
                conversation_timeout_count += 1
                
                if conversation_timeout_count == 6:  # 30 seconds of silence
                    # First timeout - gentle prompt
                    prompts = {
                        'sophia': "I'm still here if you have more questions, Sophia!",
                        'eladriel': "Still here for more dinosaur fun, Eladriel! What's next?"
                    }
                    self.speak(prompts.get(user, "I'm still listening if you have more to say!"), user)
                    print(f"‚è∞ Waiting for {user.title()} to continue... (30 seconds left)")
                    
                elif conversation_timeout_count >= max_timeouts:
                    # 1 minute timeout - end conversation gracefully
                    timeout_messages = {
                        'sophia': "I'll be here whenever you need me, Sophia. Just step in front of the camera or say 'Miley' to chat again!",
                        'eladriel': "I'll be waiting for more adventures, Eladriel! Just show your face to the camera or say 'Dino' when you're ready!"
                    }
                    self.speak(timeout_messages.get(user, "I'll be here when you need me. Just show your face or call my name!"), user)
                    conversation_active = False
        
        self.current_user = None
        logger.info(f"üé§ Automatic conversation with {user.title()} ended")
        print("üé§ Returning to face detection and wake word listening mode...")

    def start_face_recognition(self):
        """Start the background face recognition system."""
        if not self.face_recognition_active:
            self.face_recognition_active = True
            self.face_recognition_thread = threading.Thread(target=self.handle_face_detection, daemon=True)
            self.face_recognition_thread.start()
            logger.info("üé≠ Face recognition system started")

    def stop_face_recognition(self):
        """Stop the background face recognition system."""
        if self.face_recognition_active:
            self.face_recognition_active = False
            if self.face_recognition_thread:
                self.face_recognition_thread.join(timeout=2)
            logger.info("üé≠ Face recognition system stopped")

    def speak(self, text: str, user: Optional[str] = None):
        """Convert text to speech with user-specific voice settings."""
        try:
            # Use personalized TTS engine for each user
            if user and user in self.users:
                tts_engine = self.users[user]['tts_engine']
                logger.info(f"Speaking to {user}: {text}")
                tts_engine.say(text)
                tts_engine.runAndWait()
            else:
                # Default to Sophia's engine if no user specified
                logger.info(f"Speaking (default): {text}")
                self.sophia_tts.say(text)
                self.sophia_tts.runAndWait()
            
        except Exception as e:
            logger.error(f"TTS Error: {e}")

    def listen_for_speech(self, timeout: int = 5) -> Optional[str]:
        """Listen for speech input and convert to text."""
        try:
            with sr.Microphone() as source:
                logger.info("Listening for speech...")
                
                # Adjust for ambient noise
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                
                # Listen for audio
                audio = self.recognizer.listen(source, timeout=timeout, phrase_time_limit=10)
                
                # Convert speech to text
                text = self.recognizer.recognize_google(audio)
                logger.info(f"Recognized speech: {text}")
                return text.lower()
                
        except sr.WaitTimeoutError:
            logger.info("No speech detected within timeout")
            return None
        except sr.UnknownValueError:
            logger.info("Could not understand audio")
            return None
        except sr.RequestError as e:
            logger.error(f"Speech recognition error: {e}")
            return None

    async def process_with_openai(self, text: str, user: str) -> str:
        """Process user input with OpenAI and return response."""
        try:
            # Create a personalized system prompt based on user
            user_info = self.users.get(user, {})
            personality = user_info.get('personality', 'helpful and friendly')
            
            system_prompt = f"""You are a helpful AI assistant speaking to {user_info.get('name', user.title())}. 
            Be {personality}. Keep responses friendly, age-appropriate, and engaging for children. 
            Be encouraging and educational when possible. Keep responses concise but informative."""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return "I'm sorry, I'm having trouble understanding right now. Can you try again?"

    def handle_special_commands(self, user_input: str, user: str) -> Optional[str]:
        """Handle special commands for each user."""
        user_input_lower = user_input.lower()
        
        # Parent-specific admin commands
        if user == 'parent':
            if any(phrase in user_input_lower for phrase in ['status report', 'system status', 'report']):
                return self.get_system_status()
            
            elif any(phrase in user_input_lower for phrase in ['system check', 'health check', 'diagnostic']):
                return self.run_system_diagnostic()
            
            elif any(phrase in user_input_lower for phrase in ['quiet mode on', 'enable quiet mode', 'whisper mode']):
                return self.enable_quiet_mode()
            
            elif any(phrase in user_input_lower for phrase in ['quiet mode off', 'disable quiet mode', 'normal volume']):
                return self.disable_quiet_mode()
            
            elif any(phrase in user_input_lower for phrase in ['check on kids', 'kids status', 'children']):
                return self.check_kids_status()
        
        # Universal object identification commands for all users - expanded with natural phrases
        object_identification_phrases = [
            'identify this', 'what is this', 'tell me about this', 'what am i holding',
            'look', 'look at this', 'look at the camera', 'can you see this',
            'guess what this is', 'guess what i\'m holding', 'can you recognize',
            'can you identify', 'what do you see', 'recognize this',
            'see what i have', 'check this out', 'look what i found'
        ]
        
        if any(phrase in user_input_lower for phrase in object_identification_phrases):
            return self.handle_object_identification(user)
        
        # Eladriel's special dinosaur commands (keep existing functionality)
        if user == 'eladriel':
            if any(phrase in user_input_lower for phrase in ['identify dinosaur', 'what is this dinosaur', 'look at this dinosaur']):
                return self.handle_dinosaur_identification()
            
            elif any(phrase in user_input_lower for phrase in ['show camera', 'camera preview', 'can you see']):
                return self.handle_camera_preview()
            
            elif any(phrase in user_input_lower for phrase in ['dinosaur tips', 'how to show', 'tips']):
                return self.dinosaur_identifier.get_dinosaur_tips()
        
        # General help commands for all users
        if any(phrase in user_input_lower for phrase in ['help', 'what can you do', 'commands']):
            return self.get_help_message(user)
        
        return None
    
    def handle_object_identification(self, user: str) -> str:
        """Handle universal object identification for any user."""
        try:
            user_name = user.title()
            self.speak(f"Awesome {user_name}! Let me see what you're showing me! Hold it steady in front of the camera...", user)
            
            # Give user time to position the object
            import time
            time.sleep(3)
            
            # Capture and identify the object
            result = self.object_identifier.capture_and_identify(user)
            
            if result["success"]:
                return result["message"]
            else:
                return f"Hmm, I had trouble seeing your object clearly. {result['message']} Try holding it closer to the camera with good lighting!"
                
        except Exception as e:
            logger.error(f"Error in object identification: {e}")
            return "Oops! Something went wrong with the camera. Let's try again later!"
    
    def handle_dinosaur_identification(self) -> str:
        """Handle dinosaur identification for Eladriel (specialized)."""
        try:
            self.speak("Awesome! Let me see your dinosaur! Hold it steady in front of the camera...", 'eladriel')
            
            # Give Eladriel time to position the dinosaur
            import time
            time.sleep(3)
            
            # Capture and identify
            result = self.dinosaur_identifier.capture_and_identify()
            
            if result["success"]:
                return result["message"]
            else:
                return f"Hmm, I had trouble seeing your dinosaur. {result['message']} Try holding it closer to the camera!"
                
        except Exception as e:
            logger.error(f"Error in dinosaur identification: {e}")
            return "Oops! Something went wrong with the camera. Let's try again later!"
    
    def handle_camera_preview(self) -> str:
        """Show camera preview for users."""
        try:
            self.speak("Let me show you what I can see through my camera!", self.current_user)
            success = self.object_identifier.show_camera_preview(duration=5)
            
            if success:
                return "Did you see the camera window? That's what I can see! Now you know where to hold your objects!"
            else:
                return "Sorry, I couldn't show you the camera preview. Maybe the camera isn't working right now."
                
        except Exception as e:
            logger.error(f"Error showing camera preview: {e}")
            return "I had trouble with the camera preview. Let's try again later!"
    
    def get_help_message(self, user: str) -> str:
        """Get help message for each user."""
        if user == 'sophia':
            return """Hi Sophia! Here's what I can help you with:
            
‚Ä¢ Ask me questions about anything you're curious about
‚Ä¢ Get help with homework or learning
‚Ä¢ Hear fun facts and stories
‚Ä¢ Chat about your day

üîç OBJECT IDENTIFICATION:
‚Ä¢ Say "What is this?" or "Identify this" - I'll tell you all about any object you show me!
‚Ä¢ Learn about colors, materials, history, and fun facts
‚Ä¢ Perfect for exploring household items, toys, books, and more!

üí° CONVERSATION MODES:
‚Ä¢ AUTOMATIC: Just step in front of the camera - I'll start listening immediately!
‚Ä¢ VOICE ACTIVATED: Say 'Miley' if I don't see you
‚Ä¢ No need to repeat wake words during conversation
‚Ä¢ Say 'goodbye' to end, or I'll timeout after 1 minute of silence

üëÅÔ∏è FACE RECOGNITION:
‚Ä¢ I can see and recognize your face!
‚Ä¢ Automatic conversation starts when I see you
‚Ä¢ No wake words needed when you're visible!
‚Ä¢ Just step away or say 'goodbye' to end

Ask me anything or show me any object you're curious about!"""
        
        elif user == 'eladriel':
            return """Hey Eladriel! I'm your dinosaur-loving assistant! Here's what I can do:
            
ü¶ï DINOSAUR FEATURES:
‚Ä¢ Say "identify dinosaur" - I'll use my camera to identify your dinosaur toys!
‚Ä¢ Say "show me camera" - See what my camera can see
‚Ä¢ Say "dinosaur tips" - Get tips for better dinosaur identification

üîç UNIVERSAL OBJECT IDENTIFICATION:
‚Ä¢ Say "What is this?" or "Identify this" - I'll identify ANY object you show me!
‚Ä¢ Learn about toys, tools, household items, nature objects, and more!
‚Ä¢ I'll connect things to dinosaurs and adventures when possible!
‚Ä¢ Perfect for exploring everything around you!

üåü GENERAL FEATURES:
‚Ä¢ Ask me questions about dinosaurs, animals, or anything!
‚Ä¢ Get amazing facts about prehistoric creatures
‚Ä¢ Learn about different time periods

üí° CONVERSATION MODES:
‚Ä¢ AUTOMATIC: Just step in front of the camera - I'll start listening immediately!
‚Ä¢ VOICE ACTIVATED: Say 'Dino' if I don't see you
‚Ä¢ No need to repeat wake words during conversation
‚Ä¢ Say 'goodbye' to end, or I'll timeout after 1 minute of silence

üëÅÔ∏è FACE RECOGNITION:
‚Ä¢ I can see and recognize your face!
‚Ä¢ Automatic conversation starts when I see you
‚Ä¢ Perfect for showing me dinosaurs and other objects - no wake words needed!
‚Ä¢ Just step away or say 'goodbye' to end

What do you want to explore today? Show me anything you've discovered! üöÄ"""
        
        elif user == 'parent':
            return """Parent Mode Active - Advanced Features Available:

üîß SYSTEM COMMANDS:
‚Ä¢ "Status report" - Get system health and usage statistics
‚Ä¢ "System check" - Run diagnostic tests on all components
‚Ä¢ "Quiet mode on/off" - Control volume for nighttime use

üë∂ CHILD MONITORING:
‚Ä¢ "Check on kids" - Review recent activity and interactions
‚Ä¢ Face recognition shows when children are detected
‚Ä¢ Conversation logs available for review

üîç OBJECT IDENTIFICATION:
‚Ä¢ Same advanced object identification as the kids
‚Ä¢ "What is this?" works for any household item
‚Ä¢ Great for identifying unknown objects or tools

üí° CONVERSATION MODES:
‚Ä¢ VOICE ACTIVATED: Say 'Assistant' to activate
‚Ä¢ FACE RECOGNITION: Automatic activation when you're detected
‚Ä¢ Extended timeout (no rush like with kids)
‚Ä¢ Professional, efficient responses

üõ†Ô∏è TECHNICAL FEATURES:
‚Ä¢ Full access to camera and audio systems
‚Ä¢ Real-time system monitoring
‚Ä¢ Error reporting and troubleshooting
‚Ä¢ Configuration adjustments

All standard features available with enhanced capabilities for household management."""
        
        return "I'm here to help! Just ask me anything you're curious about or show me any object!"

    def get_system_status(self) -> str:
        """Provide system status report for parent mode."""
        try:
            import psutil
            import time
            
            # Get system metrics
            cpu_usage = psutil.cpu_percent(interval=1)
            memory_info = psutil.virtual_memory()
            disk_info = psutil.disk_usage('/')
            
            # Get AI assistant specific status
            face_recognition_status = "Active" if self.face_recognition_active else "Inactive"
            camera_status = "Connected" if self.face_detector.cap and self.face_detector.cap.isOpened() else "Disconnected"
            
            # Get recent activity
            current_time = time.strftime("%I:%M %p")
            
            status_report = f"""System Status Report - {current_time}

üñ•Ô∏è SYSTEM HEALTH:
‚Ä¢ CPU Usage: {cpu_usage}%
‚Ä¢ Memory: {memory_info.percent}% used ({memory_info.available // (1024**3)} GB available)
‚Ä¢ Storage: {disk_info.percent}% used

ü§ñ AI ASSISTANT STATUS:
‚Ä¢ Face Recognition: {face_recognition_status}
‚Ä¢ Camera: {camera_status}
‚Ä¢ Current User: {self.current_user or 'None (Standby)'}
‚Ä¢ Wake Words: Miley (Sophia), Dino (Eladriel), Assistant (Parent)

üìä OPERATIONAL STATUS:
‚Ä¢ Speech Recognition: Functional
‚Ä¢ Text-to-Speech: Premium OpenAI voices active
‚Ä¢ Object Identification: Ready
‚Ä¢ Dinosaur Recognition: Ready for Eladriel

All systems operational. Running smoothly."""
            
            return status_report
            
        except Exception as e:
            logger.error(f"Error getting system status: {e}")
            return "Status report unavailable. System monitoring tools may not be installed."

    def run_system_diagnostic(self) -> str:
        """Run system diagnostic tests for parent mode."""
        try:
            diagnostic_results = []
            
            # Test microphone
            mic_test = self.audio_manager.test_microphone()
            diagnostic_results.append(f"üé§ Microphone: {'‚úÖ Pass' if mic_test else '‚ùå Fail'}")
            
            # Test camera
            camera_test = self.face_detector.cap and self.face_detector.cap.isOpened()
            diagnostic_results.append(f"üì∑ Camera: {'‚úÖ Pass' if camera_test else '‚ùå Fail'}")
            
            # Test OpenAI connection
            try:
                test_response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=5
                )
                openai_test = True
            except:
                openai_test = False
            diagnostic_results.append(f"ü§ñ OpenAI API: {'‚úÖ Pass' if openai_test else '‚ùå Fail'}")
            
            # Test face recognition
            face_test = self.face_detector is not None
            diagnostic_results.append(f"üëÅÔ∏è Face Recognition: {'‚úÖ Pass' if face_test else '‚ùå Fail'}")
            
            # Test TTS engines
            tts_test = self.sophia_tts is not None and self.eladriel_tts is not None
            diagnostic_results.append(f"üó£Ô∏è Text-to-Speech: {'‚úÖ Pass' if tts_test else '‚ùå Fail'}")
            
            results_text = "\n".join(diagnostic_results)
            return f"""System Diagnostic Complete:

{results_text}

Overall Status: {'‚úÖ All systems operational' if all(['‚úÖ' in result for result in diagnostic_results]) else '‚ö†Ô∏è Some issues detected'}"""
            
        except Exception as e:
            logger.error(f"Error running diagnostics: {e}")
            return "‚ùå Diagnostic test failed. Unable to complete system check."

    def enable_quiet_mode(self) -> str:
        """Enable quiet mode with reduced volume and slower speech."""
        try:
            self.quiet_mode = True
            
            # Reduce volume and slow down speech for all TTS engines
            engines = [self.sophia_tts, self.eladriel_tts]
            for engine in engines:
                engine.setProperty('volume', 0.3)  # 30% volume
                current_rate = engine.getProperty('rate')
                engine.setProperty('rate', max(100, int(current_rate * 0.7)))  # Slower speech
            
            current_hour = datetime.now().hour
            if current_hour >= 21 or current_hour <= 6:  # 9 PM to 6 AM
                return "Quiet mode enabled. Speaking softly to avoid waking the children. Volume reduced to 30%."
            else:
                return "Quiet mode enabled. Volume reduced to 30% and speaking more slowly."
            
        except Exception as e:
            logger.error(f"Error enabling quiet mode: {e}")
            return "Error enabling quiet mode. Please try again."

    def disable_quiet_mode(self) -> str:
        """Disable quiet mode and restore normal volume and speech rate."""
        try:
            # Restore normal volume and speech rate for all TTS engines
            engines = [self.sophia_tts, self.eladriel_tts]
            for engine in engines:
                engine.setProperty('volume', 0.8)  # 80% volume
                engine.setProperty('rate', 200)  # Normal speech rate
            
            self.quiet_mode = False
            return "Quiet mode disabled. Volume restored to normal levels."
            
        except Exception as e:
            logger.error(f"Error disabling quiet mode: {e}")
            return "Error disabling quiet mode. Please try again."

    def check_kids_status(self) -> str:
        """Check on kids' recent activity and interactions."""
        try:
            current_time = time.strftime("%I:%M %p")
            
            # Check if kids are currently detected
            kids_present = []
            for user in ['sophia', 'eladriel']:
                if user in self.last_face_greeting:
                    last_seen_time = self.last_face_greeting[user]
                    time_since = time.time() - last_seen_time
                    if time_since < 300:  # Within last 5 minutes
                        kids_present.append(f"{user.title()} (seen {int(time_since//60)} min ago)")
            
            status_message = f"""Kids Status Report - {current_time}

üë∂ RECENT ACTIVITY:
"""
            
            if kids_present:
                status_message += f"‚Ä¢ Currently detected: {', '.join(kids_present)}\n"
            else:
                status_message += "‚Ä¢ No children detected in last 5 minutes\n"
            
            status_message += f"""
üé≠ FACE RECOGNITION:
‚Ä¢ Face detection system: {'Active' if self.face_recognition_active else 'Inactive'}
‚Ä¢ Auto-conversation: {'In progress' if self.current_user else 'Standby mode'}

üîß SYSTEM STATUS:
‚Ä¢ All child-safe features operational
‚Ä¢ Wake words active: 'Miley' (Sophia), 'Dino' (Eladriel)
‚Ä¢ Ready for immediate interaction when kids appear

Everything looks good for when the children wake up!"""
            
            return status_message
            
        except Exception as e:
            logger.error(f"Error checking kids status: {e}")
            return "Unable to retrieve kids status information."

    def is_conversation_ending(self, user_input: str) -> bool:
        """Check if the user wants to end the conversation."""
        ending_phrases = [
            'goodbye', 'bye', 'see you later', 'talk to you later', 
            'that\'s all', 'thanks', 'thank you', 'stop', 'exit',
            'done', 'finished', 'end conversation', 'go away'
        ]
        
        user_input_lower = user_input.lower()
        return any(phrase in user_input_lower for phrase in ending_phrases)

    def handle_user_interaction(self, user: str):
        """Handle the complete interaction flow with natural conversation mode."""
        self.current_user = user
        user_info = self.users[user]
        
        # Get greeting (fresh for parent mode to check current time)
        if user == 'parent':
            greeting = self.get_parent_greeting()
        else:
            greeting = user_info['greeting']
        
        # Greet the user
        self.speak(greeting, user)
        
        # Start conversation loop - keep listening until user says goodbye
        conversation_active = True
        conversation_timeout_count = 0
        max_timeouts = 2  # Allow 2 timeouts before ending conversation
        
        while conversation_active and self.running:
            # Listen for their request with a reasonable timeout
            user_input = self.listen_for_speech(timeout=8)
            
            if user_input:
                conversation_timeout_count = 0  # Reset timeout counter
                
                # Check if user wants to end conversation
                if self.is_conversation_ending(user_input):
                    farewell_messages = {
                        'sophia': "Goodbye Sophia! I'm always here when you need me. Have a wonderful day!",
                        'eladriel': "See you later Eladriel! Keep exploring and learning about dinosaurs! Roar!",
                        'parent': "Goodbye! Parent mode deactivated. All systems remain operational for the children. Call 'Assistant' anytime you need me."
                    }
                    self.speak(farewell_messages.get(user, "Goodbye! Talk to you soon!"), user)
                    conversation_active = False
                    break
                
                # Check for special commands first
                special_response = self.handle_special_commands(user_input, user)
                
                if special_response:
                    self.speak(special_response, user)
                else:
                    # Process with OpenAI for regular conversation
                    import asyncio
                    try:
                        response = asyncio.run(self.process_with_openai(user_input, user))
                        self.speak(response, user)
                    except Exception as e:
                        logger.error(f"Error processing request: {e}")
                        self.speak("I'm sorry, something went wrong. Let me try again.", user)
                
                # After responding, give a subtle cue that we're still listening
                time.sleep(0.5)  # Brief pause
                print(f"üí¨ Still chatting with {user.title()}... (say 'goodbye' to end)")
                
            else:
                # No speech detected
                conversation_timeout_count += 1
                
                if conversation_timeout_count == 1:
                    # First timeout - gentle prompt
                    prompts = {
                        'sophia': "I'm still here if you have more questions, Sophia!",
                        'eladriel': "Still here for more dinosaur fun, Eladriel! What's next?",
                        'parent': "I'm still here and ready to assist. Any additional requests?"
                    }
                    self.speak(prompts.get(user, "I'm still listening if you have more to say!"), user)
                    print(f"‚è∞ Waiting for {user.title()} to continue...")
                    
                elif conversation_timeout_count >= max_timeouts:
                    # Multiple timeouts - end conversation gracefully
                    goodbye_messages = {
                        'sophia': "I'll be here whenever you need me, Sophia. Just say 'Miley' to chat again!",
                        'eladriel': "I'll be waiting for more dinosaur adventures, Eladriel! Just say 'Dino' when you're ready!",
                        'parent': "Returning to standby mode. Say 'Assistant' anytime for immediate assistance."
                    }
                    self.speak(goodbye_messages.get(user, "I'll be here when you need me. Just call my name!"), user)
                    conversation_active = False
        
        self.current_user = None
        print("üé§ Conversation ended. Listening for wake words again...")

    def run(self):
        """Main loop - listen for wake words and handle natural conversations with face recognition."""
        self.running = True
        logger.info("AI Assistant started - Listening for wake words...")
        
        # Start face recognition system
        self.start_face_recognition()
        
        print("ü§ñ AI Assistant is now running with AUTOMATIC CONVERSATION MODE!")
        print("üì¢ How to interact:")
        print("   ‚Ä¢ AUTOMATIC: Just step in front of the camera!")
        print("   ‚Ä¢ VOICE: Say 'Miley' (Sophia), 'Dino' (Eladriel), or 'Assistant' (Parent)")
        print("üí° NEW FEATURES:")
        print("   ‚Ä¢ Face detection automatically starts conversations!")
        print("   ‚Ä¢ Universal object identification - show me anything!")
        print("   ‚Ä¢ No wake words needed when you're visible!")
        print("   ‚Ä¢ 1-minute timeout returns to wake word mode")
        print("   ‚Ä¢ Say 'goodbye' to end conversations anytime")
        print("üîç Object identification: Say 'What is this?' with any object!")
        print("üëÅÔ∏è Face recognition active - I can see Sophia and Eladriel!")
        print("üë®‚Äçüíº Parent Mode: Say 'Assistant' for admin features and quiet mode!")
        print("üé§ Listening for faces and wake words...")
        
        try:
            while self.running:
                # Listen for wake words (only when no one is in conversation)
                if not self.current_user:
                    detected_user = self.wake_word_detector.listen_for_wake_word()
                    
                    if detected_user:
                        logger.info(f"Wake word detected for: {detected_user}")
                        print(f"üëã Hello {detected_user.title()}! Starting voice-activated conversation...")
                        
                        # Handle the user interaction with conversation mode
                        self.handle_user_interaction(detected_user)
                else:
                    # Someone is in conversation, just wait
                    time.sleep(0.5)
                
                time.sleep(0.1)  # Small delay to prevent excessive CPU usage
                
        except KeyboardInterrupt:
            logger.info("Shutting down AI Assistant...")
            self.stop()
        except Exception as e:
            logger.error(f"Unexpected error in main loop: {e}")
            self.stop()

    def stop(self):
        """Gracefully shutdown the assistant."""
        self.running = False
        self.wake_word_detector.stop()
        self.stop_face_recognition()
        
        # Cleanup object identification resources
        try:
            self.object_identifier.cleanup()
            self.dinosaur_identifier.cleanup()
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
        
        logger.info("AI Assistant stopped")
        print("üëã AI Assistant stopped. Goodbye!")

if __name__ == "__main__":
    assistant = AIAssistant()
    assistant.run() 